---
title: "Stats Unit10"
author: "Steve Bramhall"
date: "October 29, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
reg.conf.intervals <- function(x, y) {
  n <- length(y)        # Find length of y to use as sample size
  lm.model <- lm(y ~ x) # Fit linear model
  
  # Extract fitted coefficients from model object
  b0 <- lm.model$coefficients[1]
  b1 <- lm.model$coefficients[2]
  
  # Find SSE and MSE
  sse <- sum((y - lm.model$fitted.values)^2)
  mse <- sse / (n - 2)
  
  t.val <- qt(0.975, n - 2) # Calculate critical t-value
  
  # Fit linear model with extracted coefficients
  x_new <- 1:max(x)
  y.fit <- b1 * x_new + b0
  
  # Find the standard error of the regression line
  mean.se <- sqrt(sum((y - y.fit)^2) / (n - 2)) * sqrt(1 / n + (x - mean(x))^2 / sum((x - mean(x))^2))
  
  # Fit a new linear model that extends past the given data points (for plotting)
  x_new2 <- 1:max(x + 100)
  y.fit2 <- b1 * x_new2 + b0
  
  # Warnings of mismatched lengths are suppressed
  conf.slope.upper <- suppressWarnings(y.fit2 + t.val * mean.se)
  conf.slope.lower <- suppressWarnings(y.fit2 - t.val * mean.se)
  
  # Collect the computed confidence bands into a data.frame and name the colums
  conf.bands <- data.frame(cbind(conf.slope.lower, conf.slope.upper))
  colnames(conf.bands) <- c('Lower Confidence Band', 'Upper Confidence Band')
  
  # Plot the fitted linear regression line and the computed confidence bands
  plot(x, y, cex = 1.75, pch = 21, bg = 'gray')
  lines(y.fit2, col = 'black', lwd = 2)
  lines(conf.bands[1], col = 'blue', lty = 2, lwd = 2)
  lines(conf.bands[2], col = 'blue', lty = 2, lwd = 2)
  
  return(bands)
}

#conf.intervals <- reg.conf.intervals(cars$speed, cars$dist)
```

#### 1a. Provide a scatterplot with 99% confidence intervals of the regression line and 99% prediction intervals of the regression line.  
```{r}
# Read data from csv file
data1 <- read.csv("..\\..\\DoingDataScience\\HW9\\InputFiles\\Beers.csv",header=TRUE,sep=",",stringsAsFactors = TRUE, encoding = "UTF-8")
names(data1) <- c("BeerName","BeerID","ABV","IBU","BreweryID","BeerStyle","Ounces") # rename table columns

# get min/max values for newx range
summary(data1$IBU) 
newx <- seq(4, 138, by=20)

# linear model
linear.regress.model <- lm(ABV ~ IBU, data=data1)

# plot linear model
plot(data1$IBU, data1$ABV, xlab="ABV", ylab="IBU", main="Regression")
abline(linear.regress.model, col="lightblue")

# add confidence interval lines
conf.interval <- predict(linear.regress.model,newdata=data.frame(IBU=newx),interval="confidence",level = 0.99)
lines(newx, conf.interval[,2], col="blue", lty=2)
lines(newx, conf.interval[,3], col="blue", lty=2)

# add prediction interval lines
pred.interval <- predict(linear.regress.model,newdata=data.frame(IBU=newx),interval="prediction",level = 0.99)
lines(newx, pred.interval[,2], col="orange", lty=2)
lines(newx, pred.interval[,3], col="orange", lty=2)
```
##### Code ref: https://rpubs.com/Bio-Geek/71339

#### 1b. Provide	a table showing the t-statistics and p-values for the significance of the regression parameters beta0 and beta1
```{r}
summary(linear.regress.model)
```
#### 1c. Using the output in (b), show all 6 steps of each hypothesis test. 
1. Beta1 = 0, Beta1 not equal to 0
```{r}
n <- length(data1$IBU) 
 t.val <- qt(0.975, n - 2) # Calculate critical t-value
```
2. Critical Value = 
3. Beta0 t-statistic = 
4. p-value =
5. reject Ho
6. The evidence suggests at the alpha = .01 level of significance (p-value = ) the data is not linearly correlated. We are 99% confident that when the means IBU increases by 1, the mean ABV increases between XX and XX points. Causation. Population inference.
#### 1d. State the regression equation. Be careful to use the mean Tcell or predicted Tcell, rather than just Tcell.
#### y = mx + b
#### 1e. Interpret the slope in the model (regression equation).
####     For every 1-point increase in the mean science score, the estimated mean math score increases .5968 points.
#### 1f. Interpret the y-intercept in the model (regression equation). 
####     y-intercept: If the mean science score is 0 points, the estimated mean math score is 21.7.
#### 1g. Find and interpret the 99% confidence interval for the mean t-cell response conditional on a stone mass of 4.5 grams.
```{r}
conf.interval.1g <- predict(linear.regress.model, newdata=data.frame(IBU=4.5), interval="confidence",level = 0.99)
conf.interval.1g
```
####     The 99% confidence interval for the mean t-cell response on a stone mass of 4.5g is ( , )
#### 1h. Find and interpret the 99% prediction interval for the mean t-cell response conditional on a stone mass of 4.5 grams.
```{r}
pred.interval.1g <- predict(linear.regress.model, newdata=data.frame(IBU=4.5), interval="prediction",level = 0.99)
pred.interval.1g
```
####     The 99% prediction interval for the mean t-cell response on a stone mass of 4.5g is ( , )
####1i1a. From "eye-balling" the graph, the 99% calibration interval for the mean t-cell response of 0.3 appears to be roughly ( , )
####1i1b. From "eye-balling" the graph, the 99% calibration interval for a single t-cell response of 0.3 appears to be roughly ( , )
####1i2a. Use SW to abtain the results for 1i1a.
```{r}
calibrate(linear.regress.model,y0=4.5,level=0.99,interval="inversion",mean.response=TRUE)   # get mean response
```
####1i2b. Use SW to abtain the results for 1i1b.
```{r}
calibrate(linear.regress.model,y0=4.5,level=0.99,interval="inversion",mean.response=FALSE)  # get single response
```
####1i3a. Interpret the results for 1i1a.
####1i3b. Interpret the results for 1i1b.
####1j. Provide a scatterplot of residuals.

