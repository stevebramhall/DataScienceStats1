---
title: "Stats Unit10"
author: "Steve Bramhall"
date: "October 29, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(investr) # for calibration
library(MASS)    # for studentized residuals
```

```{r echo=FALSE}
reg.conf.intervals <- function(x, y) {
  n <- length(y)        # Find length of y to use as sample size
  lm.model <- lm(y ~ x) # Fit linear model
  
  # Extract fitted coefficients from model object
  b0 <- lm.model$coefficients[1]
  b1 <- lm.model$coefficients[2]
  
  # Find SSE and MSE
  sse <- sum((y - lm.model$fitted.values)^2)
  mse <- sse / (n - 2)
  ase <- sse / n
  
  t.val <- qt(0.975, n - 2) # Calculate critical t-value
  
  # Fit linear model with extracted coefficients
  x_new <- 1:max(x)
  y.fit <- b1 * x_new + b0
  
  # Find the standard error of the regression line
  mean.se <- sqrt(sum((y - y.fit)^2) / (n - 2)) * sqrt(1 / n + (x - mean(x))^2 / sum((x - mean(x))^2))
  
  # Fit a new linear model that extends past the given data points (for plotting)
  x_new2 <- 1:max(x + 100)
  y.fit2 <- b1 * x_new2 + b0
  
  # Warnings of mismatched lengths are suppressed
  conf.slope.upper <- suppressWarnings(y.fit2 + t.val * mean.se)
  conf.slope.lower <- suppressWarnings(y.fit2 - t.val * mean.se)
  
  # Collect the computed confidence bands into a data.frame and name the colums
  conf.bands <- data.frame(cbind(conf.slope.lower, conf.slope.upper))
  colnames(conf.bands) <- c('Lower Confidence Band', 'Upper Confidence Band')
  
  # Plot the fitted linear regression line and the computed confidence bands
  plot(x, y, cex = 1.75, pch = 21, bg = 'gray')
  lines(y.fit2, col = 'black', lwd = 2)
  lines(conf.bands[1], col = 'blue', lty = 2, lwd = 2)
  lines(conf.bands[2], col = 'blue', lty = 2, lwd = 2)
  
  return(bands)
}

#conf.intervals <- reg.conf.intervals(cars$speed, cars$dist)
```

#### 1a. Provide a scatterplot with 99% confidence intervals of the regression line and 99% prediction intervals of the regression line.  
```{r}
# Read data from csv file
data1 <- read.csv(".\\Male Display Data Set.csv",header=TRUE,sep=",",stringsAsFactors = TRUE, encoding = "UTF-8")
names(data1) <- c("Mass","TCell") # rename table columns

# get min/max values for newx range
summary(data1$Mass) 
newx <- seq(2, 10, by=0.5)
newy <- seq(0, 0.7, by=0.1)

# linear model
linear.regress.model <- lm(TCell ~ Mass, data=data1)

# plot linear model
plot(data1$Mass, data1$TCel, ylim=c(-0.2,0.8),xlab="Mass (g)", ylab="T-Cell (in mm)", main="Regression")
abline(linear.regress.model, col="lightblue")

# add confidence interval lines
conf.interval <- predict(linear.regress.model,newdata=data.frame(Mass=newx),interval="confidence",level = 0.99)
lines(newx, conf.interval[,2], col="blue", lty=2)
lines(newx, conf.interval[,3], col="blue", lty=2)

# add prediction interval lines
pred.interval <- predict(linear.regress.model,newdata=data.frame(Mass=newx),interval="prediction",level = 0.99)
lines(newx, pred.interval[,2], col="orange", lty=2)
lines(newx, pred.interval[,3], col="orange", lty=2)
```

##### Code ref: https://rpubs.com/Bio-Geek/71339

#### 1b. Provide	a table showing the t-statistics and p-values for the significance of the regression parameters beta0 and beta1
```{r}
summary(linear.regress.model)
```
#### 1c. Using the output in (b), show all 6 steps of each hypothesis test. 
1. Beta1 = 0, Beta1 not equal to 0
```{r}
n <- length(data1$Mass) 
t.val <- qt(0.995, n - 2) # Calculate critical t-value
t.val
```
2. Critical Value = 2.861
3. Beta0 t-statistic = 3.084
4. p-value = 0.00611
5. reject Ho
```{r}
confint(linear.regress.model)
```

6. The evidence suggests at the alpha = .01 level of significance (p-value = ) the data is not linearly correlated. We are 99% confident that when the mean Mass increases by 1g, the mean T-Cell increases between 0.0105 and 0.0551 in mm. This is an observational study so we cannot make any inferences about causation. It is unknown whether a random sample was used so any inferences to population are limited to the male black-eared wheaters in this study.

#### 1d. State the regression equation. Be careful to use the mean Tcell or predicted Tcell, rather than just Tcell.

##### T-Cell = 0.03282*stone mass + 0.0875

#### 1e. Interpret the slope in the model (regression equation).

##### For every 1 gram increase in the mean mass, the estimated mean T-Cell value increases 0.03282 in mm.

#### 1f. Interpret the y-intercept in the model (regression equation). 

##### y-intercept: If the mean mass 0 grams, the estimated mean T-Cell is 0.0875 in mm.

#### 1g. Find and interpret the 99% confidence interval for the mean t-cell response conditional on a stone mass of 4.5 grams.

```{r}
conf.interval.1g <- predict(linear.regress.model, newdata=data.frame(Mass=4.5), interval="confidence",level = 0.99)
conf.interval.1g
```
##### The 99% confidence interval for the mean t-cell response on a stone mass of 4.5g is (0.1386,0.3318)

#### 1h. Find and interpret the 99% prediction interval for the mean t-cell response conditional on a stone mass of 4.5 grams.
```{r}
pred.interval.1g <- predict(linear.regress.model, newdata=data.frame(Mass=4.5), interval="prediction",level = 0.99)
pred.interval.1g
```
####     The 99% prediction interval for the mean t-cell response on a stone mass of 4.5g is (-0.01593,0.4863). Since mass can't be negative (0,0.4863).
####1i1a. From "eye-balling" the graph, the 99% calibration interval for the mean t-cell response of 0.3 appears to be roughly ( , )
####1i1b. From "eye-balling" the graph, the 99% calibration interval for a single t-cell response of 0.3 appears to be roughly ( , )
####1i2a. Use SW to abtain the results for 1i1a.
```{r}
calibrate(linear.regress.model,y0=4.5,level=0.99,interval="inversion",mean.response=TRUE)   # get mean response
```
####1i2b. Use SW to abtain the results for 1i1b.
```{r}
calibrate(linear.regress.model,y0=4.5,level=0.99,interval="inversion",mean.response=FALSE)  # get single response
```
####1i3a. Interpret the results for 1i1a.

####1i3b. Interpret the results for 1i1b.

####1j. Provide a scatterplot of residuals.
```{r}
resids=resid(linear.regress.model)                       # get the residuals
plot(data1$Mass,resids,                                  # plot the residuals
     main="Residual Plot: T-Cell vs Mass",               # add plot title
     xlab="Mass (g)",                                    # add x-axis label
     ylab="T-Cell Residuals")                            # add y-axis label

studentized.resids=studres(linear.regress.model)
plot(data1$Mass,studentized.resids,                      # plot the studentized residuals
     main="Studenteized Residual Plot: T-Cell vs Mass",  # add plot title
     xlab="Mass (g)",                                    # add x-axis label
     ylab="T-Cell Studentized Residuals")                # add y-axis label

```

####1k. Provide a histogram of residuals.
```{r}
hist(resids,
     main="Normal Curve Over Residuals Histogram",       # add plot title
     xlab="Mass",                                        # add x-axis label
     ylab="T-Cell")                                      # add y-axis label
curve(dnorm(x,mean=mean(resids),sd=sd(resids)),          # add normal curve
      col="darkblue",lwd=2,add=TRUE,yaxt="n")

hist(studentized.resids,
     main="Normal Curve Over Studentized Residuals Histogram", # add plot title
     xlab="Mass",                                        # add x-axis label
     ylab="T-Cell")                                      # add y-axis label
curve(dnorm(x,mean=mean(studentized.resids),sd=sd(studentized.resids)), # add normal curve
      col="darkgreen",lwd=2,add=TRUE,yaxt="n")
```


####1l. Provide a measure of the proportion of variation in the response that is accounted for by the explanatory variable. Interpret this measure.